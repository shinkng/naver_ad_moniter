import requests
from bs4 import BeautifulSoup

keywords = [
    "ê²½ë„ë¥¼ ê¸°ë‹¤ë¦¬ë©° ott",
    "ë¬´ë£Œì˜í™”",
    "ott"
]

target_domains = ["filecity.me", "fileis.co"]

base_url = "https://search.naver.com/search.naver"
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

results = []

for keyword in keywords:
    params = {
        'where': 'nexearch',
        'query': keyword
    }

    response = requests.get(base_url, params=params, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')

    power_links = soup.select('#power_link_body > ul > li')

    print(f"\n{'='*80}")
    print(f"í‚¤ì›Œë“œ: {keyword}")

    # 1 íŒŒì›Œë§í¬ ì¡´ì¬ ì—¬ë¶€
    if not power_links:
        print("íŒŒì›Œë§í¬ ì—†ìŒ")
        continue

    print(f"íŒŒì›Œë§í¬ ì¡´ì¬ (ì´ {len(power_links)}ê°œ)")

    # 2 ìˆœë²ˆ + ë„ë©”ì¸ ì¶”ì¶œ
    for idx, li in enumerate(power_links, start=1):
        a = li.select_one('a.lnk_url')
        if not a:
            continue

        domain = a.get_text(strip=True).rstrip('/')

        # 3 íƒ€ê²Ÿ ë„ë©”ì¸ì¸ì§€ ì²´í¬
        if domain in target_domains:
            result = {
                'keyword': keyword,
                'domain': domain,
                'rank': idx
            }
            results.append(result)

            print(f"ğŸ¯ ë°œê²¬: {domain} â†’ {idx}ë²ˆì§¸")

# ìµœì¢… ìš”ì•½
print(f"\n{'='*80}")
print("ìµœì¢… ê²°ê³¼ ìš”ì•½")

if not results:
    print("íƒ€ê²Ÿ ë„ë©”ì¸ ë…¸ì¶œ ì—†ìŒ")
else:
    for r in results:
        print(
            f"í‚¤ì›Œë“œ='{r['keyword']}' | "
            f"ë„ë©”ì¸='{r['domain']}' | "
            f"ìˆœìœ„={r['rank']}"
        )
